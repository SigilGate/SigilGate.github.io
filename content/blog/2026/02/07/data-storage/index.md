---
title: "Система хранения данных"
slug: "система-хранения-данных"
date: 2026-02-07T12:00:00+00:00
draft: false
summary: "Хотел завести пару учеток — в итоге спроектировал систему хранения данных. Типичные выходные."
tags: ["архитектура", "данные", "документация"]
---

Эти выходные я планировал посвятить простым и понятным вещам: завести пару новых учетных записей для подключения новых пользователей и клиентских устройств. Ну и заодно автоматизировать этот процесс — чтобы в следующий раз не делать все руками.

Не так много работы. Всего лишь добавить пару учеток в конфиги.

Казалось бы.

На самом деле, параллельно я продолжаю растаскивать монорепозиторий, в котором за время работы над прототипом скопилось все подряд. Там же, в общей куче, лежат и данные пользователей — конфиги, учетные записи, параметры соединений. Первая мысль была простой: перетащить все это в приватную репу и хранить там, периодически обновляя вручную. Но объемы информации растут, и то, что делалось все это время руками на коленке — пора уже превращать в нормальный процесс.

А чтобы нормально автоматизировать типовые задачи — создание пользователей, настройку соединений, генерацию клиентских конфигов для входных нод — первое, что нужно, это где-то хранить все эти данные. Системно. Так, чтобы с ними можно было работать и обрабатывать программно.

И вот тут, на данном этапе, у меня было весьма туманное представление о том, как это организовать.

## Два противоречивых требования

Потому что тут возникают сразу два противоположных требования.

С одной стороны — данные должны храниться централизованно. К ним всегда должен быть доступ, даже в самые критические моменты, в случае отказа и потери доступа ко всем узлам сети. Даже если случится катастрофа — данные должны быть восстановлены, и сеть должна возродиться аки птица Феникс из пепла.

С другой стороны — сеть по своей природе децентрализована и должна быть устойчива к отказам. А данные, необходимые для оперативного контроля и управления — должны быть распределены по узлам.

На этом моменте моя голова обычно взрывалась, и я говорил себе:

> Я подумаю об этом завтра.

## Завтра настало

И видимо это «завтра» наконец-то наступило. Я сел и всерьез задумался о том, как технично можно организовать хранение данных в нашей сети.

После многочасовых размышлений и длительных консультаций с друзьями была выбрана **гибридная архитектура** из двух слоев:

- **KV-кластер** на базе `etcd` — распределенное оперативное хранилище, развернутое на Core-нодах. Быстрый доступ к текущему состоянию сети, строгая консистентность через протокол Raft, устойчивость к отказу отдельных узлов. Это то, с чем сеть работает в реальном времени.
- **Git-репозиторий** — версионирование данных и бэкап. Хранит желаемое состояние инфраструктуры, обеспечивает версионирование, аудит изменений и — самое главное — возможность полного восстановления сети с нуля. Даже после потери всей оперативной инфраструктуры.

Двунаправленная синхронизация связывает оба слоя: Git → KV при развертывании и восстановлении, KV → Git — для периодической фиксации оперативных изменений.

Такой подход закрывает оба требования одновременно: децентрализованное оперативное управление — через KV-кластер, гарантированная сохранность и восстановление — через Git.

Пока это проект — реализация впереди. Но общие принципы сформулированы и задокументированы. Подробности — в разделе [«Хранение данных»]({{< ref "docs/data_storage" >}}) документации.

---

P.S. Учетных записей новых я так и не завел — потому что у меня всего одна пара рук (надо признать, весьма кривых) и одна пара глаз (надо отметить, уже весьма красных). Но выходные еще не кончились — так что надежда есть.
